{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "Jobs = pd.read_csv(\"JobsFE.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine relevant columns into a single text column\n",
    "Jobs[\"job_text\"] = (\n",
    "    Jobs[\"position\"].astype(str) + \" \" +\n",
    "    Jobs[\"job_role_and_duties\"].astype(str) + \" \" +\n",
    "    Jobs[\"requisite_skill\"].astype(str)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SBERT model\n",
    "MODEL = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\", device=\"cpu\")\n",
    "job_texts = Jobs[\"job_text\"].tolist()\n",
    "job_embeddings = MODEL.encode(job_texts, convert_to_numpy=True)\n",
    "job_embeddings = job_embeddings / np.linalg.norm(job_embeddings, axis=1, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to determine the optimal number of clusters using BIC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bic_method(data, max_clusters):\n",
    "    bic_scores = []\n",
    "    K = range(1, max_clusters + 1)\n",
    "    for k in K:\n",
    "        gmm = GaussianMixture(n_components=k, random_state=42)\n",
    "        gmm.fit(data)\n",
    "        bic_scores.append(gmm.bic(data))\n",
    "    \n",
    "    # Plot BIC scores\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(K, bic_scores, \"bo-\", markersize=8)\n",
    "    plt.xlabel(\"Number of Clusters (k)\")\n",
    "    plt.ylabel(\"BIC Score\")\n",
    "    plt.title(\"BIC Method for Optimal k\")\n",
    "    plt.show()\n",
    "\n",
    "# Apply the BIC Method\n",
    "bic_method(job_embeddings, max_clusters=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set optimal number of clusters\n",
    "optimal_clusters = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform GMM clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(n_components=optimal_clusters, random_state=42)\n",
    "cluster_labels = gmm.fit_predict(job_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jobs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the cluster labels as a new column to the dataset\n",
    "Jobs[\"cluster\"] = cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated dataset with cluster labels\n",
    "Jobs.to_csv(\"Jobs_with_clusters_GMM.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example resume text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_text = \"\"\"Yomna Waleed Elsayed Ahmed Hassan\n",
    "Junior machine learning engineering\n",
    "yomnawaleed2002@gmail.com\n",
    "EGYPT, AlGharbia goverment, tanta city.\n",
    "Yomna Waleed\n",
    "yomna_waleed\n",
    "+201118064546\n",
    "19/05/2002\n",
    "YomnaWaleed\n",
    "yomna_waleed\n",
    "EDUCATION\n",
    "Faculty of Engineering, Department of Computers and Control, Tanta university 2020 – 2025\n",
    "Tanta, Egypt\n",
    "TRAINING\n",
    "Manara Tech 04/2023 – present\n",
    "PROFILE\n",
    "I am a dedicated engineering student specializing in Computer and Automatic Control, with a strong academic background and practical experience in\n",
    "programming and software development. I excelled in my coursework, achieving an excellent degree in my second year and a very good grade in my\n",
    "first year. I have a solid foundation in Python programming and libraries essential for data science and machine learning, including NumPy, pandas,\n",
    "and Matplotlib. My participation in the International Collegiate Programming Contest (ICPC) as a team leader has further honed my problem-solving\n",
    "skills.\n",
    "I am actively expanding my expertise in machine learning (ML), particularly in Natural Language Processing (NLP) and Generative AI, having\n",
    "completed supervised machine learning courses and gained practical experience with various deep learning architectures, including DNNs, RNNs, and\n",
    "CNNs. My background also includes full-stack development using React.js and Node.js, enabling me to effectively integrate machine learning models\n",
    "into web applications.\n",
    "SKILLS\n",
    "Programming Languages & Technologies:\n",
    "•Python: Proficient\n",
    "•C++: Proficient\n",
    "•React.js: Competent\n",
    "•Node.js: Amateur\n",
    "•HTML/CSS: Competent\n",
    "Data Structures & Algorithms\n",
    "•Proficient in implementing algorithms and data structures in Python\n",
    "and C++\n",
    "•Strong foundation in problem-solving techniques, demonstrated\n",
    "through participation in competitive programming\n",
    "Machine Learning & Data Science:\n",
    "•Libraries: NumPy, pandas, Matplotlib (Competent)\n",
    "•Machine Learning: Supervised learning (regression, classification)\n",
    "using Scikit-learn (Competent)\n",
    "•Deep Learning: Familiar with TensorFlow and PyTorch (Amateur)\n",
    "•Architectures: DNN, RNN, CNN, Object Detection, Word Detection,\n",
    "Transfer Learning (Amateur)\n",
    "•Generative AI: Currently learning (Amateur)\n",
    "SOFT SKILLS\n",
    "Project management and leadership\n",
    "While I was working on the maze game project, I managed to divide the\n",
    "tasks among the group, although this was challenging because we chose\n",
    "a three-dimensional game that was beyond what we had learned.\n",
    "Thinking outside the box\n",
    "\"While choosing a project, I always try to challenge myself and attempt\n",
    "something that is difficult for others to implement, such as selecting a\n",
    "three-dimensional game instead of a two-dimensional one, despite the\n",
    "difficulty of it. I successfully completed the game.\"\n",
    "PROJECTS\n",
    "Email-SMS-Spam-Classifier, Developed a supervised machine learning model to classify emails and SMS messages as\n",
    "spam or not using Python and Scikit-learn.\n",
    "08/2024 – 08/2024\n",
    "Egypt-House-Price-Prediction--Regression-Project, Built a regression model to predict house prices based on\n",
    "various features, implemented with an HTML interface for user interaction.\n",
    "08/2024 – 08/2024\n",
    "Nonogram Puzzle, Created a Nonogram puzzle generator that utilizes backtracking methods and a CSP approach to\n",
    "solve generated puzzles. My contribution was in developing the solver algorithm.\n",
    "2024\n",
    "3d maze game, Developed a 3D maze game using OpenGL and Python, where players navigate to collect coins and solve\n",
    "puzzles. My role included building the player's movement mechanics and 3D interactions.\n",
    "2023\n",
    "Railway Ticket booking, Designed and implemented a train ticket booking system using Node.js, React.js, and MS SQL\n",
    "for database management, allowing users to book and cancel tickets.\n",
    "2023\n",
    "simple memory gain, Created a memory game using React.js that challenges users to find pairs of matching images. 2023\n",
    "CERTIFICATES\n",
    "ICPC Qualification 2022\n",
    "Problem Solving\n",
    "Back-end enineering using Nodejs and Express\n",
    "Ideal Student Recognition\n",
    "ICPC qualification 2023\n",
    "Zero to Hero in Front-end Development with React\n",
    "Fullstack Engineering with React and Node.js\n",
    "Volunteer Work at College and University\n",
    "LANGUAGES\n",
    "English\n",
    "EF SET English Certificate\n",
    "French\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the resume text\n",
    "resume_embedding = MODEL.encode([resume_text], convert_to_numpy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the resume text\n",
    "resume_embedding = MODEL.encode([resume_text], convert_to_numpy=True)\n",
    "resume_cluster = gmm.predict(resume_embedding)[0]\n",
    "print(f\"The resume belongs to cluster: {resume_cluster}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to evaluate model results using GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_results(recommended_jobs, resume_cluster, Jobs):\n",
    "    \"\"\"\n",
    "    Evaluates the model results by checking how many recommended jobs\n",
    "    belong to the same cluster as the resume.\n",
    "    \"\"\"\n",
    "    # Check if recommended_jobs is empty\n",
    "    if not recommended_jobs:\n",
    "        print(\"No recommended jobs found.\")\n",
    "        return 0.0\n",
    "\n",
    "    # Extract cluster labels of recommended jobs\n",
    "    recommended_clusters = []\n",
    "    for job in recommended_jobs:\n",
    "        try:\n",
    "            job_id = job[\"Job Id\"]  # Ensure \"Job Id\" is the correct key\n",
    "            cluster = Jobs.loc[Jobs[\"Job Id\"] == job_id, \"cluster\"].values[0]\n",
    "            recommended_clusters.append(cluster)\n",
    "        except KeyError:\n",
    "            print(f\"Warning: 'Job Id' key not found in job: {job}\")\n",
    "            continue\n",
    "        except IndexError:\n",
    "            print(f\"Warning: Job ID {job_id} not found in Jobs DataFrame.\")\n",
    "            continue\n",
    "\n",
    "    # Check if recommended_clusters is empty\n",
    "    if not recommended_clusters:\n",
    "        print(\"No valid clusters found for recommended jobs.\")\n",
    "        return 0.0\n",
    "\n",
    "    # Calculate cluster purity\n",
    "    cluster_purity = np.sum(np.array(recommended_clusters) == resume_cluster) / len(recommended_clusters)\n",
    "\n",
    "    print(f\"Clusters of recommended Jobs: {recommended_clusters}\")\n",
    "    print(f\"Cluster of resume is {resume_cluster}\")\n",
    "    print(f\"Percentage of recommended jobs in the same cluster: {cluster_purity:.2%}\")\n",
    "    return cluster_purity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate the accuracy of SBERT model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SBERTmodel import JobRecommendationSystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the system with job data\n",
    "import time\n",
    "import json\n",
    "start = time.time()\n",
    "recommender_SBERT = JobRecommendationSystem(\"Jobs_with_clusters_GMM.csv\")\n",
    "recommended_jobs_SBERT = recommender_SBERT.recommend_jobs(resume_text, top_n=20)\n",
    "end = time.time()\n",
    "print(f\" the Execution of SBERT model is {end - start}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jobs = pd.read_csv(\"Jobs_with_clusters_GMM.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the evaluation metrics \n",
    "SBERT_cluster_Purity = evaluate_model_results(recommended_jobs_SBERT[\"recommended_jobs\"], resume_cluster,Jobs)\n",
    "print(f\"Cluster Purity: {SBERT_cluster_Purity:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_jobs_SBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate the accuracy of FASTTEXT model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FastText.FastTextmodel import JobRecommendationSystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the system with job data\n",
    "import time\n",
    "start = time.time()\n",
    "recommender_fasttext = JobRecommendationSystem(\"Jobs_with_clusters_GMM.csv\")\n",
    "recommended_jobs_fasttext = recommender_fasttext.recommend_jobs(resume_text, top_n=20)\n",
    "end = time.time()\n",
    "print(f\" the Excution time is {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_jobs_fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the evaluation metrics \n",
    "FastText_cluster_Purity = evaluate_model_results(recommended_jobs_fasttext[\"recommended_jobs\"], resume_cluster)\n",
    "print(f\"Cluster Purity: {FastText_cluster_Purity:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate the accuracy of BM25 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BM25model import JobRecommendationSystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the system with job data\n",
    "import time\n",
    "import json\n",
    "start = time.time()\n",
    "recommender_BM25 = JobRecommendationSystem(\"Jobs_with_clusters_GMM.csv\")\n",
    "recommended_jobs_BM25 = recommender_BM25.recommend_jobs(resume_text, top_n=20)\n",
    "end = time.time()\n",
    "print(f\"the time of excution is {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_jobs_BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the evaluation metrics \n",
    "BM25_cluster_Purity = evaluate_model_results(recommended_jobs_BM25[\"recommended_jobs\"], resume_cluster)\n",
    "print(f\"Cluster Purity: {BM25_cluster_Purity:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate the accuracy of TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TFIDFmodel import JobRecommendationSystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the system with job data\n",
    "import time\n",
    "import json\n",
    "start = time.time()\n",
    "recommender_TFIDF = JobRecommendationSystem(\"Jobs_with_clusters_GMM.csv\")\n",
    "recommended_jobs_TFIDF = recommender_TFIDF.recommend_jobs(resume_text, top_n=20)\n",
    "end = time.time()\n",
    "print(f\"the time of excution is {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_jobs_TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the evaluation metrics \n",
    "TFIDF_cluster_Purity = evaluate_model_results(recommended_jobs_TFIDF[\"recommended_jobs\"], resume_cluster)\n",
    "print(f\"Cluster Purity: {TFIDF_cluster_Purity:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate the accuracy of KNN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from KNNmodel import JobRecommendationSystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the system with job data\n",
    "import time\n",
    "start = time.time()\n",
    "recommender_KNN = JobRecommendationSystem(\"Jobs_with_clusters_GMM.csv\")\n",
    "recommended_jobs_KNN = recommender_KNN.recommend_jobs(resume_text, top_n=20)\n",
    "end = time.time()\n",
    "print(f\"the time of excution is {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_jobs_KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the evaluation metrics \n",
    "KNN_cluster_Purity = evaluate_model_results(recommended_jobs_KNN[\"recommended_jobs\"], resume_cluster)\n",
    "print(f\"Cluster Purity: {KNN_cluster_Purity:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate the accuracy of LDA model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LDAmodel import JobRecommendationSystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the system with job data\n",
    "import time\n",
    "start = time.time()\n",
    "recommender_LDA = JobRecommendationSystem(\"Jobs_with_clusters_GMM.csv\")\n",
    "recommended_jobs_LDA = recommender_LDA.recommend_jobs(resume_text, top_n=20)\n",
    "end = time.time()\n",
    "print(f\"the time of excution is {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_jobs_LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the evaluation metrics \n",
    "LDA_cluster_Purity = evaluate_model_results(recommended_jobs_LDA[\"recommended_jobs\"], resume_cluster)\n",
    "print(f\"Cluster Purity: {LDA_cluster_Purity:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
